{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3045f545-9856-49a3-848f-cbe56bbb99c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\arcturus\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb148b9c-3079-4b5d-a0e0-19e3d6ded09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff5f1d25-0aab-4c91-844a-ba51b99e9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Location  \\\n",
      "0  Data Analyst , Senior Data Analyst , Data Anal...  Bangalore   \n",
      "1                                       Data Analyst  Bangalore   \n",
      "2  Data Analyst (Power BI, Python, SQL)- Internal...  Bangalore   \n",
      "3                               Data Analyst Opening  Bangalore   \n",
      "4        Data Analyst Fresher and Experience Vacancy  Bangalore   \n",
      "5                              Clinical Data Analyst  Bangalore   \n",
      "6                           Data Analyst Recruitment  Bangalore   \n",
      "7                           Data Analyst Recruitment  Bangalore   \n",
      "8                                   Business Analyst  Bangalore   \n",
      "9                                        MIS Analyst  Bangalore   \n",
      "\n",
      "                                  Company   Experience  \n",
      "0                       appsoft solutions   0 to 4 Yrs  \n",
      "1         valenta bpo solutions pvt. ltd.   4 to 5 Yrs  \n",
      "2       talent leads hr solutions pvt ltd   3 to 8 Yrs  \n",
      "3                     radhika enterprises   0 to 4 Yrs  \n",
      "4                     radhika enterprises   0 to 4 Yrs  \n",
      "5                           techno endura    0 to 1 Yr  \n",
      "6                     radhika enterprises   0 to 4 Yrs  \n",
      "7                     radhika enterprises   0 to 4 Yrs  \n",
      "8  mackenzie modern it solutions priva...   4 to 6 Yrs  \n",
      "9             quess corp (magna infotech)  8 to 13 Yrs  \n"
     ]
    }
   ],
   "source": [
    "'''Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "website https://www.shine.com/ '''\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.shine.com/')\n",
    "# using this i am facing error\n",
    "# time.sleep(30)\n",
    "# designation=driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "# designation.send_keys('Data Analyst')\n",
    "try:\n",
    "    designation = WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.CLASS_NAME, \"form-control\")))\n",
    "    designation.send_keys('Data Analyst')\n",
    "    location = WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.XPATH, \"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")))\n",
    "    location.send_keys('Bangalore')\n",
    "    search=driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "    search.click()\n",
    "\n",
    "    job_title=[]\n",
    "    job_location=[]\n",
    "    company_name=[]\n",
    "    experience_required=[]\n",
    "    title=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]/h2/a')\n",
    "    for i in title[0:10]:\n",
    "        job_title.append(i.text)\n",
    "    loc=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "    for l in loc[0:10]:\n",
    "        loc_text=l.text.split('\\n')\n",
    "        job_location.append(loc_text[0])\n",
    "\n",
    "    comp=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "    for c in comp[0:10]:\n",
    "        company_name.append(c.text)\n",
    "    exp=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "    for e in exp[0:10]:\n",
    "        experience_required.append(e.text)\n",
    "\n",
    "    df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company':company_name,'Experience':experience_required})\n",
    "    print(df)\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Element not found within the specified timeout.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24ec85cd-beed-4ba9-8ca5-308f9b9c2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Title  \\\n",
      "0                                   Data Scientist   \n",
      "1                        Data Scientist, Marketing   \n",
      "2                                   Data Scientist   \n",
      "3       Data Scientist-Senior Associate - P&T Labs   \n",
      "4                                   Data Scientist   \n",
      "5                                   Data Scientist   \n",
      "6  Associate Manager / Senior Data Scientist (CPG)   \n",
      "7       NLP Data Scientist - Real World Data (RWD)   \n",
      "8                           Data Science Associate   \n",
      "9                                   Data Scientist   \n",
      "\n",
      "                      Comapny Name  \\\n",
      "0                    Tech Mahindra   \n",
      "1                         Coursera   \n",
      "2                          Infosys   \n",
      "3      PwC Service Delivery Center   \n",
      "4                         Deloitte   \n",
      "5  Tata Consultancy Services (TCS)   \n",
      "6                        Trendence   \n",
      "7         Agilite Global Solutions   \n",
      "8                    ZS Associates   \n",
      "9                            Wipro   \n",
      "\n",
      "                                            Location Experience  \n",
      "0                Hybrid - Hyderabad, Pune, Bengaluru   6-10 Yrs  \n",
      "1  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...    4-6 Yrs  \n",
      "2                Hybrid - Hyderabad, Pune, Bengaluru    4-8 Yrs  \n",
      "3                       Mumbai, Hyderabad, Bengaluru    4-6 Yrs  \n",
      "4                     Mumbai, Bengaluru, Delhi / NCR    4-9 Yrs  \n",
      "5       Bangalore Rural, Kolkata, Mumbai (All Areas)    5-9 Yrs  \n",
      "6  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   5-11 Yrs  \n",
      "7  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...    7-8 Yrs  \n",
      "8                 Hybrid - Pune, Gurugram, Bengaluru    1-3 Yrs  \n",
      "9                           Pune, Chennai, Bengaluru   6-11 Yrs  \n"
     ]
    }
   ],
   "source": [
    "''' Q2.Write a python program to scrape data for ““Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "website https://www.naukri.com/  '''\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')\n",
    "try:\n",
    "    title=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "    title.send_keys('Data Scientist')\n",
    "    location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "    location.send_keys('Bangalore')\n",
    "    search=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "    search.click()\n",
    "\n",
    "    job_title=[]\n",
    "    job_loc=[]\n",
    "    company=[]\n",
    "    experience=[]\n",
    "    titles = WebDriverWait(driver, 30).until(EC.visibility_of_all_elements_located((By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')))\n",
    "    for t in titles[0:10]:\n",
    "        job_title.append(t.text)\n",
    "    loc=driver.find_elements(By.XPATH,'//span[@class=\"locWdth\"]')\n",
    "    for l in loc[0:10]:\n",
    "        job_loc.append(l.text)\n",
    "    comp=driver.find_elements(By.XPATH,'//span[@class=\" comp-dtls-wrap\"]/a[1]')\n",
    "    for c in comp[0:10]:\n",
    "        company.append(c.text)\n",
    "    exp=driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "    for e in exp[0:10]:\n",
    "        experience.append(e.text)\n",
    "    df=pd.DataFrame({'Title':job_title,'Comapny Name':company,'Location':job_loc,'Experience':experience})\n",
    "    print(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print('error time related',e)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "957b6346-15e6-4ea9-b6d1-894eb45a8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Brand                                Product Description   Price  \\\n",
      "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹818   \n",
      "1   VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...    ₹836   \n",
      "2        Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹470   \n",
      "3        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹503   \n",
      "4        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹499   \n",
      "..            ...                                                ...     ...   \n",
      "95         PIRASO           UV Protection Over-sized Sunglasses (64)    ₹379   \n",
      "96  VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...    ₹792   \n",
      "97    john jacobs  Polarized, UV Protection Rectangular Sunglasse...  ₹3,599   \n",
      "98       Fastrack             UV Protection Wayfarer Sunglasses (57)    ₹547   \n",
      "99      Elligator              UV Protection Aviator Sunglasses (55)    ₹299   \n",
      "\n",
      "   Discount  \n",
      "0   59% off  \n",
      "1   58% off  \n",
      "2   47% off  \n",
      "3   49% off  \n",
      "4   50% off  \n",
      "..      ...  \n",
      "95  85% off  \n",
      "96  68% off  \n",
      "97  40% off  \n",
      "98  45% off  \n",
      "99  88% off  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "''' Q3 Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "website https://www.flipkart.com/\n",
    "'''\n",
    "try:\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    thing = WebDriverWait(driver, 60).until(EC.visibility_of_element_located((By.CLASS_NAME, \"Pke_EE\")))\n",
    "    thing.send_keys('sunglasses')\n",
    "    search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div/div/div[1]/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "    search.click()\n",
    "    \n",
    "    brand=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    c=11\n",
    "    for i in range(0,3):\n",
    "        Brand=driver.find_elements(By.XPATH,'//div[@class=\"syl9yP\"]')\n",
    "        pro_desc=driver.find_elements(By.XPATH,'//div[@class=\"hCKiGj\"]/a[1]')\n",
    "        pr=driver.find_elements(By.XPATH,'//div[@class=\"Nx9bqj\"]')\n",
    "        disc=driver.find_elements(By.XPATH,'//div[@class=\"UkUFwK\"]/span')\n",
    "        if(i==2):            \n",
    "            for b,d,p in zip(Brand[0:20],pro_desc[0:20],pr[0:20]):\n",
    "                brand.append(b.text)\n",
    "                product_desc.append(d.text)\n",
    "                price.append(p.text)\n",
    "            for disc in disc[0:20]:\n",
    "                discount.append(disc.text)\n",
    "        else:\n",
    "            for b,d,p in zip(Brand,pro_desc,pr):\n",
    "                brand.append(b.text)\n",
    "                product_desc.append(d.text)\n",
    "                price.append(p.text)\n",
    "            for disc in disc:\n",
    "                if(disc==''):\n",
    "                    discount.append('None')\n",
    "                else:\n",
    "                    discount.append(disc.text)\n",
    "        next_button=driver.find_element(By.XPATH,f'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[{c}]/span')\n",
    "        next_button.click()\n",
    "        time.sleep(4)\n",
    "        c=11+1\n",
    "    df=pd.DataFrame({'Brand':brand,'Product Description':product_desc,'Price':price,'Discount':discount})\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print('something error',e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
